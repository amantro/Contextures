# config_hierarchical.yaml
# Global settings or general training parameters
global:
  seed: 42
  device: cuda # or cpu
  results_dir: results/temp

# TODO: finish feature preprocessing config
feature_preprocessing:
  name: Identity
 
train:
  num_epochs: 20
  batch_size: 256

losses:
  name: SVDLoRA
  parameters:
    exp_parameterization: squared
    temperature: 1.0

# assumes that x and a have the same encoder structure for now
encoder:
  name: MLPEncoder
  parameters:
    output_dim: 128
    hidden_dims: [128, 128, 128]

contexts:
  name: scarf
  parameters:
    num_contexts: 10 # r contexts a per input x
    distribution: uniform
    corruption_rate: 0.6
